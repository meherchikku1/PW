{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b03e6c19-1ea3-4b8c-89f6-69a87fe167c4",
   "metadata": {},
   "source": [
    "Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d4ed35-8ddd-4182-be4e-122d958ac61f",
   "metadata": {},
   "source": [
    "ANS:\n",
    "Web scraping is the process of extracting data from websites. It involves using software tools to fetch the HTML code of a webpage and then parse it to extract the desired information. This information can be text, images, links, or any other content present on the webpage.\n",
    "\n",
    "* areas where Web Scraping is used to get data are following:-\n",
    "1. Data Collection: Web scraping is commonly used to gather large amounts of data from websites efficiently. This data can be used for various purposes such as market research, competitor analysis, or building datasets for machine learning models.\n",
    "\n",
    "2. Content Aggregation: Websites often contain valuable information spread across multiple pages or sources. Web scraping can be used to aggregate this content into a single database or platform for easier access and consumption.\n",
    "\n",
    "3. Monitoring and Tracking: Businesses use web scraping to monitor changes on websites, such as price changes, product availability, or news updates. This allows them to stay informed about developments in their industry or track the performance of their competitors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32713e72-2b48-4144-b478-203e3c62ecfd",
   "metadata": {},
   "source": [
    "Q2. What are the different methods used for Web Scraping?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2498f0ec-9189-454c-a375-7e8e18522402",
   "metadata": {},
   "source": [
    "1. HTML Parsing: Extracting data by parsing HTML code.\n",
    "2. APIs: Utilizing APIs provided by websites for structured data retrieval.\n",
    "3. Automated Browsing: Mimicking human browsing behavior using tools like Selenium.\n",
    "4. Text Pattern Matching: Employing regular expressions or natural language processing to extract desired information from text content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821b44df-6053-4816-8cf8-475bc0103c71",
   "metadata": {},
   "source": [
    "Q3. What is Beautiful Soup? Why is it used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab6df01-4e10-4dc1-b36b-73e45ca9df41",
   "metadata": {},
   "source": [
    "Beautiful Soup is a Python library for parsing HTML and XML documents. It provides tools for navigating, searching, and modifying the parsed tree, making it easier to extract data from web pages. Beautiful Soup is widely used for web scraping tasks because of its simplicity, flexibility, and robustness. It helps developers to quickly and efficiently scrape web pages, extract relevant information, and incorporate it into their applications or analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15fcc88-0d2e-4521-bafd-11b1a50e513c",
   "metadata": {},
   "source": [
    "Q4. Why is flask used in this Web Scraping project?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e83039-fb35-4450-8616-f492fed87ca4",
   "metadata": {},
   "source": [
    "Flask is used in web scraping projects for its ability to quickly develop web applications. It integrates well with Python scraping scripts, facilitates routing, URL handling, and template rendering. This allows developers to create user interfaces for input, display, and interaction with scraped data efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5cbfea-09a0-4e10-99cf-12ca60a8ba22",
   "metadata": {},
   "source": [
    "Q5. Write the names of AWS services used in this project. Also, explain the use of each service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdc2eaa-cc7d-4e7a-8663-4a75bc48ad55",
   "metadata": {},
   "source": [
    "1. Amazon EC2 (Elastic Compute Cloud): Provides scalable computing capacity in the cloud, often used to host web scraping scripts and applications.\n",
    "\n",
    "2. Amazon S3 (Simple Storage Service): Offers scalable object storage for storing scraped data, logs, or any other files generated during the scraping process.\n",
    "\n",
    "3. Amazon RDS (Relational Database Service): Provides managed relational databases, which can be used to store structured data extracted from web scraping tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22aac61-d490-437c-9fc6-b7f68b5c51da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0540785d-7e38-47fe-9f2e-443ab5408a48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f13a8e-a197-41be-a2be-2f1d3cb29c39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
